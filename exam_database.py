#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¸€å»ºå†å¹´çœŸé¢˜æ•°æ®åº“æ„å»ºç¨‹åº
åŠŸèƒ½ï¼šå°†è§£æçš„çœŸé¢˜æ•°æ®æ„å»ºä¸ºå¯æŸ¥è¯¢çš„æ•°æ®åº“
"""

import json
import sqlite3
from pathlib import Path
from typing import Dict, List
from datetime import datetime


class ExamDatabase:
    """çœŸé¢˜æ•°æ®åº“"""

    def __init__(self, db_path: str = "./data/exam_questions.db"):
        self.db_path = Path(db_path)
        self.db_path.parent.mkdir(parents=True, exist_ok=True)
        self.conn = None

    def connect(self):
        """è¿æ¥æ•°æ®åº“"""
        # ä½¿ç”¨ check_same_thread=False å…è®¸å¤šçº¿ç¨‹è®¿é—®
        self.conn = sqlite3.connect(self.db_path, check_same_thread=False)
        self.conn.row_factory = sqlite3.Row
        return self.conn

    def _get_connection(self):
        """è·å–æ•°æ®åº“è¿æ¥ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰"""
        if self.conn is None:
            self.connect()
        return self.conn
    
    def create_tables(self):
        """åˆ›å»ºæ•°æ®è¡¨"""
        conn = self._get_connection()
        cursor = conn.cursor()

        # åˆ›å»ºé¢˜ç›®è¡¨
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS questions (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                year INTEGER NOT NULL,
                subject TEXT NOT NULL,
                number INTEGER NOT NULL,
                type TEXT NOT NULL,
                question TEXT NOT NULL,
                answer TEXT,
                analysis TEXT,
                difficulty TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                UNIQUE(year, subject, number)
            )
        ''')

        # åˆ›å»ºé€‰é¡¹è¡¨
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS options (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                question_id INTEGER NOT NULL,
                option_key TEXT NOT NULL,
                option_value TEXT NOT NULL,
                FOREIGN KEY (question_id) REFERENCES questions(id),
                UNIQUE(question_id, option_key)
            )
        ''')

        # åˆ›å»ºçŸ¥è¯†ç‚¹è¡¨
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS knowledge_points (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                question_id INTEGER NOT NULL,
                point TEXT NOT NULL,
                FOREIGN KEY (question_id) REFERENCES questions(id)
            )
        ''')

        # åˆ›å»ºæ¡ˆä¾‹é¢˜è¡¨
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS case_studies (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                year INTEGER NOT NULL,
                subject TEXT NOT NULL,
                case_number INTEGER NOT NULL,
                title TEXT NOT NULL,
                background TEXT NOT NULL,
                score INTEGER,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                UNIQUE(year, subject, case_number)
            )
        ''')

        # åˆ›å»ºæ¡ˆä¾‹é¢˜å°é—®é¢˜è¡¨
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS case_sub_questions (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                case_id INTEGER NOT NULL,
                sub_number INTEGER NOT NULL,
                question TEXT NOT NULL,
                answer TEXT,
                analysis TEXT,
                FOREIGN KEY (case_id) REFERENCES case_studies(id),
                UNIQUE(case_id, sub_number)
            )
        ''')

        # åˆ›å»ºç´¢å¼•
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_year ON questions(year)')
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_subject ON questions(subject)')
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_type ON questions(type)')
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_case_year ON case_studies(year)')
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_case_subject ON case_studies(subject)')

        conn.commit()
        print("âœ… æ•°æ®è¡¨åˆ›å»ºæˆåŠŸ")
    
    def import_from_json(self, json_file: str):
        """ä»JSONæ–‡ä»¶å¯¼å…¥æ•°æ®"""
        print(f"\nğŸ“¥ å¯¼å…¥æ•°æ®: {Path(json_file).name}")

        with open(json_file, 'r', encoding='utf-8') as f:
            data = json.load(f)

        conn = self._get_connection()
        cursor = conn.cursor()
        imported = 0
        skipped = 0
        
        for q in data['questions']:
            try:
                # æ’å…¥é¢˜ç›®
                cursor.execute('''
                    INSERT OR IGNORE INTO questions 
                    (year, subject, number, type, question, answer, analysis, difficulty)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?)
                ''', (
                    q['year'],
                    q['subject'],
                    q['number'],
                    q['type'],
                    q['question'],
                    q.get('answer'),
                    q.get('analysis'),
                    q.get('difficulty')
                ))
                
                if cursor.rowcount > 0:
                    question_id = cursor.lastrowid
                    
                    # æ’å…¥é€‰é¡¹
                    for key, value in q.get('options', {}).items():
                        cursor.execute('''
                            INSERT OR IGNORE INTO options (question_id, option_key, option_value)
                            VALUES (?, ?, ?)
                        ''', (question_id, key, value))
                    
                    # æ’å…¥çŸ¥è¯†ç‚¹
                    for point in q.get('knowledge_points', []):
                        cursor.execute('''
                            INSERT INTO knowledge_points (question_id, point)
                            VALUES (?, ?)
                        ''', (question_id, point))
                    
                    imported += 1
                else:
                    skipped += 1
                    
            except Exception as e:
                print(f"  âš ï¸  å¯¼å…¥é¢˜ç›® {q.get('number')} å¤±è´¥: {str(e)}")
                skipped += 1

        conn.commit()
        print(f"  âœ… å¯¼å…¥ {imported} é“é¢˜ç›®ï¼Œè·³è¿‡ {skipped} é“")

        return imported, skipped

    def import_case_studies_from_json(self, json_file: str):
        """ä»JSONæ–‡ä»¶å¯¼å…¥æ¡ˆä¾‹é¢˜æ•°æ®"""
        print(f"\nğŸ“¥ å¯¼å…¥æ¡ˆä¾‹é¢˜æ•°æ®: {Path(json_file).name}")

        with open(json_file, 'r', encoding='utf-8') as f:
            data = json.load(f)

        conn = self._get_connection()
        cursor = conn.cursor()
        imported_cases = 0
        imported_subs = 0
        skipped = 0

        for case in data['case_studies']:
            try:
                # æ’å…¥æ¡ˆä¾‹é¢˜
                cursor.execute('''
                    INSERT OR IGNORE INTO case_studies
                    (year, subject, case_number, title, background, score)
                    VALUES (?, ?, ?, ?, ?, ?)
                ''', (
                    case['year'],
                    case['subject'],
                    case['case_number'],
                    case['title'],
                    case['background'],
                    case.get('score')
                ))

                if cursor.rowcount > 0:
                    case_id = cursor.lastrowid

                    # æ’å…¥å°é—®é¢˜
                    for sq in case['sub_questions']:
                        cursor.execute('''
                            INSERT OR IGNORE INTO case_sub_questions
                            (case_id, sub_number, question, answer, analysis)
                            VALUES (?, ?, ?, ?, ?)
                        ''', (
                            case_id,
                            sq['sub_number'],
                            sq['question'],
                            sq.get('answer'),
                            sq.get('analysis')
                        ))
                        if cursor.rowcount > 0:
                            imported_subs += 1

                    imported_cases += 1
                else:
                    skipped += 1

            except Exception as e:
                print(f"  âš ï¸  å¯¼å…¥æ¡ˆä¾‹ {case.get('case_number')} å¤±è´¥: {str(e)}")
                skipped += 1

        conn.commit()
        print(f"  âœ… å¯¼å…¥ {imported_cases} ä¸ªæ¡ˆä¾‹ï¼Œ{imported_subs} ä¸ªå°é—®é¢˜ï¼Œè·³è¿‡ {skipped} ä¸ª")

        return imported_cases, imported_subs, skipped

    def get_statistics(self) -> Dict:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        conn = self._get_connection()
        cursor = conn.cursor()

        stats = {}

        # æ€»é¢˜ç›®æ•°ï¼ˆé€‰æ‹©é¢˜ï¼‰
        cursor.execute('SELECT COUNT(*) FROM questions')
        stats['total_questions'] = cursor.fetchone()[0]

        # æ€»æ¡ˆä¾‹æ•°
        cursor.execute('SELECT COUNT(*) FROM case_studies')
        stats['total_cases'] = cursor.fetchone()[0]

        # æ€»æ¡ˆä¾‹å°é—®é¢˜æ•°
        cursor.execute('SELECT COUNT(*) FROM case_sub_questions')
        stats['total_case_sub_questions'] = cursor.fetchone()[0]

        # æŒ‰ç§‘ç›®ç»Ÿè®¡ï¼ˆé€‰æ‹©é¢˜ï¼‰
        cursor.execute('''
            SELECT subject, COUNT(*) as count
            FROM questions
            GROUP BY subject
        ''')
        stats['by_subject'] = {row['subject']: row['count'] for row in cursor.fetchall()}

        # æŒ‰ç§‘ç›®ç»Ÿè®¡ï¼ˆæ¡ˆä¾‹é¢˜ï¼‰
        cursor.execute('''
            SELECT subject, COUNT(*) as count
            FROM case_studies
            GROUP BY subject
        ''')
        stats['cases_by_subject'] = {row['subject']: row['count'] for row in cursor.fetchall()}

        # æŒ‰å¹´ä»½ç»Ÿè®¡ï¼ˆé€‰æ‹©é¢˜ï¼‰
        cursor.execute('''
            SELECT year, COUNT(*) as count
            FROM questions
            GROUP BY year
            ORDER BY year DESC
        ''')
        stats['by_year'] = {row['year']: row['count'] for row in cursor.fetchall()}

        # æŒ‰å¹´ä»½ç»Ÿè®¡ï¼ˆæ¡ˆä¾‹é¢˜ï¼‰
        cursor.execute('''
            SELECT year, COUNT(*) as count
            FROM case_studies
            GROUP BY year
            ORDER BY year DESC
        ''')
        stats['cases_by_year'] = {row['year']: row['count'] for row in cursor.fetchall()}

        # æŒ‰é¢˜å‹ç»Ÿè®¡
        cursor.execute('''
            SELECT type, COUNT(*) as count
            FROM questions
            GROUP BY type
        ''')
        stats['by_type'] = {row['type']: row['count'] for row in cursor.fetchall()}

        return stats
    
    def search_questions(self, keyword: str = None, subject: str = None,
                        year: int = None, limit: int = 10) -> List[Dict]:
        """æœç´¢é¢˜ç›®"""
        conn = self._get_connection()
        cursor = conn.cursor()
        
        query = 'SELECT * FROM questions WHERE 1=1'
        params = []
        
        if keyword:
            query += ' AND question LIKE ?'
            params.append(f'%{keyword}%')
        
        if subject:
            query += ' AND subject = ?'
            params.append(subject)
        
        if year:
            query += ' AND year = ?'
            params.append(year)
        
        query += f' LIMIT {limit}'
        
        cursor.execute(query, params)
        
        questions = []
        for row in cursor.fetchall():
            q = dict(row)
            
            # è·å–é€‰é¡¹
            cursor.execute('SELECT option_key, option_value FROM options WHERE question_id = ?', (q['id'],))
            q['options'] = {r['option_key']: r['option_value'] for r in cursor.fetchall()}
            
            questions.append(q)
        
        return questions

    def get_questions(self, subject: str = None, year: int = None,
                     qtype: str = None, page: int = 1, page_size: int = 20) -> Dict:
        """åˆ†é¡µè·å–é¢˜ç›®"""
        conn = self._get_connection()
        cursor = conn.cursor()

        # æ„å»ºæŸ¥è¯¢æ¡ä»¶
        query = 'SELECT * FROM questions WHERE 1=1'
        count_query = 'SELECT COUNT(*) FROM questions WHERE 1=1'
        params = []

        if subject:
            query += ' AND subject = ?'
            count_query += ' AND subject = ?'
            params.append(subject)

        if year:
            query += ' AND year = ?'
            count_query += ' AND year = ?'
            params.append(year)

        if qtype:
            query += ' AND type = ?'
            count_query += ' AND type = ?'
            params.append(qtype)

        # è·å–æ€»æ•°
        cursor.execute(count_query, params)
        total = cursor.fetchone()[0]

        # åˆ†é¡µæŸ¥è¯¢
        offset = (page - 1) * page_size
        query += f' ORDER BY year DESC, number ASC LIMIT {page_size} OFFSET {offset}'

        cursor.execute(query, params)

        questions = []
        for row in cursor.fetchall():
            q = dict(row)

            # è·å–é€‰é¡¹
            cursor.execute('SELECT option_key, option_value FROM options WHERE question_id = ?', (q['id'],))
            q['options'] = {r['option_key']: r['option_value'] for r in cursor.fetchall()}

            questions.append(q)

        return {
            'questions': questions,
            'total': total,
            'page': page,
            'page_size': page_size,
            'total_pages': (total + page_size - 1) // page_size
        }

    def get_case_studies(self, subject: str = None, year: int = None,
                        page: int = 1, page_size: int = 10) -> Dict:
        """åˆ†é¡µè·å–æ¡ˆä¾‹é¢˜"""
        conn = self._get_connection()
        cursor = conn.cursor()

        # æ„å»ºæŸ¥è¯¢æ¡ä»¶
        query = 'SELECT * FROM case_studies WHERE 1=1'
        count_query = 'SELECT COUNT(*) FROM case_studies WHERE 1=1'
        params = []

        if subject:
            query += ' AND subject = ?'
            count_query += ' AND subject = ?'
            params.append(subject)

        if year:
            query += ' AND year = ?'
            count_query += ' AND year = ?'
            params.append(year)

        # è·å–æ€»æ•°
        cursor.execute(count_query, params)
        total = cursor.fetchone()[0]

        # åˆ†é¡µæŸ¥è¯¢
        offset = (page - 1) * page_size
        query += f' ORDER BY year DESC, case_number ASC LIMIT {page_size} OFFSET {offset}'

        cursor.execute(query, params)

        cases = []
        for row in cursor.fetchall():
            case = dict(row)

            # è·å–å°é—®é¢˜
            cursor.execute('''
                SELECT sub_number, question, answer, analysis
                FROM case_sub_questions
                WHERE case_id = ?
                ORDER BY sub_number
            ''', (case['id'],))

            case['sub_questions'] = [dict(r) for r in cursor.fetchall()]

            cases.append(case)

        return {
            'cases': cases,
            'total': total,
            'page': page,
            'page_size': page_size,
            'total_pages': (total + page_size - 1) // page_size
        }

    def close(self):
        """å…³é—­æ•°æ®åº“è¿æ¥"""
        if self.conn:
            self.conn.close()


def main():
    """ä¸»å‡½æ•°"""
    print("\n" + "=" * 60)
    print("ğŸ—„ï¸  ä¸€å»ºå†å¹´çœŸé¢˜æ•°æ®åº“æ„å»ºç¨‹åº")
    print("=" * 60)
    
    # åˆ›å»ºæ•°æ®åº“
    db = ExamDatabase()
    db.connect()
    db.create_tables()
    
    # å¯¼å…¥æ•°æ®
    parsed_dir = Path("./æœºç”µå†å¹´çœŸé¢˜/parsed_data")

    if not parsed_dir.exists():
        print("\nâŒ æœªæ‰¾åˆ°è§£ææ•°æ®ç›®å½•ï¼Œè¯·å…ˆè¿è¡Œ exam_parser.py")
        return

    print("\nğŸ“‚ æ‰«æè§£ææ•°æ®...")

    # å¯¼å…¥é€‰æ‹©é¢˜
    json_files = list(parsed_dir.glob("*_questions.json"))
    print(f"æ‰¾åˆ° {len(json_files)} ä¸ªé€‰æ‹©é¢˜æ•°æ®æ–‡ä»¶")

    total_imported = 0
    total_skipped = 0

    for json_file in json_files:
        imported, skipped = db.import_from_json(json_file)
        total_imported += imported
        total_skipped += skipped

    # å¯¼å…¥æ¡ˆä¾‹é¢˜
    case_files = list(parsed_dir.glob("*_æ¡ˆä¾‹é¢˜.json"))
    print(f"\næ‰¾åˆ° {len(case_files)} ä¸ªæ¡ˆä¾‹é¢˜æ•°æ®æ–‡ä»¶")

    total_cases = 0
    total_case_subs = 0
    total_case_skipped = 0

    for case_file in case_files:
        cases, subs, skipped = db.import_case_studies_from_json(case_file)
        total_cases += cases
        total_case_subs += subs
        total_case_skipped += skipped
    
    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    print("\n" + "=" * 60)
    print("ğŸ“Š æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯")
    print("=" * 60)

    stats = db.get_statistics()

    print(f"\nğŸ“ é€‰æ‹©é¢˜æ€»æ•°: {stats['total_questions']} é“")
    print(f"ğŸ“‹ æ¡ˆä¾‹é¢˜æ€»æ•°: {stats['total_cases']} ä¸ªï¼ˆ{stats['total_case_sub_questions']} ä¸ªå°é—®é¢˜ï¼‰")
    print(f"ğŸ“Š æ€»è®¡: {stats['total_questions'] + stats['total_case_sub_questions']} é“é¢˜ç›®")

    print("\nğŸ“š é€‰æ‹©é¢˜æŒ‰ç§‘ç›®ç»Ÿè®¡:")
    for subject, count in sorted(stats['by_subject'].items()):
        print(f"  {subject:12s}: {count:4d} é“")

    print("\nğŸ“‹ æ¡ˆä¾‹é¢˜æŒ‰ç§‘ç›®ç»Ÿè®¡:")
    for subject, count in sorted(stats.get('cases_by_subject', {}).items()):
        print(f"  {subject:12s}: {count:4d} ä¸ª")

    print("\nğŸ“… é€‰æ‹©é¢˜æŒ‰å¹´ä»½ç»Ÿè®¡:")
    for year, count in sorted(stats['by_year'].items(), reverse=True):
        print(f"  {year} å¹´: {count:4d} é“")

    print("\nğŸ“… æ¡ˆä¾‹é¢˜æŒ‰å¹´ä»½ç»Ÿè®¡:")
    for year, count in sorted(stats.get('cases_by_year', {}).items(), reverse=True):
        print(f"  {year} å¹´: {count:4d} ä¸ª")

    print("\nğŸ“ æŒ‰é¢˜å‹ç»Ÿè®¡:")
    for qtype, count in sorted(stats['by_type'].items()):
        print(f"  {qtype:12s}: {count:4d} é“")
    
    # æµ‹è¯•æœç´¢
    print("\n" + "=" * 60)
    print("ğŸ” æœç´¢æµ‹è¯•")
    print("=" * 60)
    
    print("\næœç´¢å…³é”®è¯: 'æ–½å·¥'")
    results = db.search_questions(keyword='æ–½å·¥', limit=3)
    for i, q in enumerate(results, 1):
        print(f"\n{i}. [{q['year']}å¹´ {q['subject']}] ç¬¬{q['number']}é¢˜ ({q['type']})")
        print(f"   {q['question'][:50]}...")
    
    db.close()
    
    print("\n" + "=" * 60)
    print("âœ… æ•°æ®åº“æ„å»ºå®Œæˆï¼")
    print("=" * 60)
    print(f"\næ•°æ®åº“æ–‡ä»¶: {db.db_path}")
    print(f"æ€»å¯¼å…¥: {total_imported} é“é¢˜ç›®")
    print(f"æ€»è·³è¿‡: {total_skipped} é“é¢˜ç›®")
    print("\nğŸ’¡ ä¸‹ä¸€æ­¥:")
    print("  1. è¿è¡Œ exam_viewer.py æŸ¥çœ‹å’Œæœç´¢é¢˜ç›®")
    print("  2. é›†æˆåˆ°AIåŠ©æ‰‹ç³»ç»Ÿ")
    print("")


if __name__ == "__main__":
    main()

